{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZU929iQLeVi"
      },
      "source": [
        "# Kelompok 5 J.A.R.V.I.S\n",
        "Dataset : HR Analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_kvHQo3Lzpo"
      },
      "source": [
        "Nama Anggota Kelompok 5 :\n",
        "1. Fikih Imam R.\n",
        "2. Mim Hanifah P.\n",
        "3. Mutia Dewi Kurniasih\n",
        "4. Nadia Putri P.\n",
        "5. Rizca Zahra\n",
        "6. Wilmay Armianty Golden Utomo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKi6pxsEMqWr"
      },
      "source": [
        "## Import Libraries List"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.0 -U\n",
        "!pip install eli5"
      ],
      "metadata": {
        "id": "hV6Cke0qJmoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aedc8b3-cce5-48c9-943c-9dbc411955bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn==1.0 in /usr/local/lib/python3.7/dist-packages (1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (1.4.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2>=3.0.0->eli5) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFuCtCkrMd4N"
      },
      "outputs": [],
      "source": [
        "# Put Our Import list\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as st\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.lines as lines\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts, RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix,classification_report, roc_auc_score, roc_curve, auc\n",
        "from lightgbm.sklearn import LGBMClassifier\n",
        "\n",
        "import six\n",
        "import sys\n",
        "sys.modules['sklearn.externals.six'] = six\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4Rbz9-xp5Mw"
      },
      "source": [
        "## <b>Context and Content</b>\n",
        "\n",
        "Sebuah perusahaan yang bergerak di bidang Big Data dan Data Science ingin merekrut ilmuwan data dari orang-orang yang berhasil lulus beberapa kursus yang diadakan oleh perusahaan. Banyak orang mendaftar untuk pelatihan perusahaan. Perusahaan ingin mengetahui kandidat mana yang benar-benar ingin bekerja untuk perusahaan setelah pelatihan atau mencari pekerjaan baru karena membantu mengurangi biaya dan waktu serta kualitas pelatihan atau perencanaan kursus dan kategorisasi kandidat. Informasi dari signup dan enrollment pendaftar berupa demografi, pendidikan, dan pengalaman.\n",
        "\n",
        "Dataset ini dirancang untuk penelitian HR dalam memahami faktor-faktor yang menyebabkan seseorang meninggalkan pekerjaan saat ini. Dengan model yang menggunakan kredensial, demografi, data pengalaman saat ini, dapat diprediksi kemungkinan seorang kandidat untuk mencari pekerjaan baru atau akan bekerja untuk perusahaan, serta menafsirkan faktor-faktor yang memengaruhi keputusan karyawan.\n",
        "\n",
        "Seluruh data dibagi menjadi data train dan test. Target tidak disertakan dalam data test tetapi data nilai target test ada di file lain. File Sample Submission sesuai dengan enrollee_id dari set tes yang disediakan juga dengan kolom: enrollee _id , target.\n",
        "\n",
        "<i>Inspiration\n",
        "- Predict the probability of a candidate will work for the company\n",
        "- Interpret model(s) such a way that illustrate which features affect candidate decision</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vToWthucLooG"
      },
      "source": [
        "## <b>STAGE 1. EDA, INSIGHTS, AND VISUALIZATION</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0gSobAmNCue"
      },
      "source": [
        "### Get the Dataset + Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNmLAkkZGZG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4437875-e834-4dc7-8a66-9d7523a00425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBo-tHQfI73E"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/aug_train.csv')\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/aug_test.csv')\n",
        "ss = pd.read_csv('/content/gdrive/MyDrive/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO4oYCVOLFlQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "16690bca-77f8-495f-cc04-7dec15b03a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data :\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-18aa5aee18cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train data :'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print('test data :')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# display(test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# #print('test answers :')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "print('train data :')\n",
        "display(train)\n",
        "# print('test data :')\n",
        "# display(test)\n",
        "# #print('test answers :')\n",
        "# #display(ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_SdRX7rPuRy"
      },
      "source": [
        "#### Features in Given Data set\n",
        "\n",
        "1. enrollee_id: Unique ID for candidate\n",
        "\n",
        "2. city: City code\n",
        "\n",
        "3. city_ development _index : Developement index of the city (scaled)\n",
        "\n",
        "4. gender: Gender of candidate\n",
        "\n",
        "5. relevent_experience: Relevant experience of candidate\n",
        "\n",
        "6. enrolled_university: Type of University course enrolled if any\n",
        "\n",
        "7. education_level: Education level of candidate\n",
        "\n",
        "8. major_discipline : Education major discipline of candidate\n",
        "\n",
        "9. experience: Candidate total experience in years\n",
        "\n",
        "10. company_size: No of employees in current employer's company\n",
        "\n",
        "11. company_type : Type of current employer\n",
        "\n",
        "12. lastnewjob: Difference in years between previous job and current job\n",
        "\n",
        "13. training_hours: training hours completed\n",
        "\n",
        "14. target: 0 – Not looking for job change, 1 – Looking for a job change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEbjth6DRVvH"
      },
      "source": [
        "Data di sini terkait dengan HR analytics suatu perusahaan, untuk memperkirakan kandidat yang mencari perubahan pekerjaan, dan faktor-faktor yang mempengaruhinya.\n",
        "\n",
        "Poin kunci utama yang perlu diperhatikan dalam dataset ini:\n",
        "\n",
        "1. Sebagian besar data bersifat kategoris\n",
        "2. Handling imbalance data\n",
        "3. Ada / tidak missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdOGH9FUQ395"
      },
      "source": [
        "#### About Train Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWciW75WKu-Z"
      },
      "source": [
        "##### Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD1gkW66RFDR"
      },
      "outputs": [],
      "source": [
        "def data_explore(dataframe):\n",
        "    print(\"DATA EXPLORATION\")\n",
        "    print('*'*80)\n",
        "    print(\"Shape of dataset : \",dataframe.shape)\n",
        "    print('*'*80)\n",
        "    print(dataframe.info())\n",
        "    print('*'*80)\n",
        "    print(\"STATISTICAL ANALYSIS OF NUMERICAL DATA\")\n",
        "    print('*'*80)\n",
        "    print(dataframe.describe().T)\n",
        "    print('*'*80)\n",
        "    print(\"STATISTICAL ANALYSIS OF CATEGORICAL DATA\")\n",
        "    print('*'*80)\n",
        "    print(dataframe.describe(exclude = ['float', 'int64']).T)\n",
        "    print('*'*80)\n",
        "    print(\"MISSING VALUES\")\n",
        "    print('*'*80)\n",
        "    print(dataframe.isna().sum().sort_values(ascending=False))\n",
        "    print('*'*80)\n",
        "    print(\"MISSING VALUES IN %\")\n",
        "    print('*'*80)\n",
        "    print(round(100* (dataframe.isnull().sum() / len(dataframe)).sort_values(ascending=False),2))\n",
        "    print('*'*80)\n",
        "    \n",
        "data_explore(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc1AcStxKNNR"
      },
      "source": [
        "##### Value Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz8qAGVGKqIB"
      },
      "source": [
        "Kita dapat memastikan pengamatan mengenai kolom-kolom categorical di atas dengan value counting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAHiJxeAJ_Eo"
      },
      "outputs": [],
      "source": [
        "nums = ['enrollee_id','city_development_index', 'training_hours', 'target']\n",
        "cats = ['city','gender','relevent_experience','enrolled_university','education_level','major_discipline','experience','company_size','company_type','last_new_job']\n",
        "for col in cats:\n",
        "    print(f'''Value count kolom {col}:''')\n",
        "    print(train[col].value_counts())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ly5ijhMpsqo"
      },
      "source": [
        "Kesimpulan tentang train data :\n",
        "\n",
        "A. Pengamatan info:\n",
        "1. Data terdiri dari 19158 baris\n",
        "2. Tampak beberapa kolom masih memiliki null/missing values (Non-Null Count < jumlah baris) seperti: `gender` (23.53%), `enrolled_university`(2.01%), `education_level` (2,40%), `major_discipline` (14.68%), `experience` (0.34%), `company_size` (30.99%), `company_type` (32.05%), dan `last_new_job` (2.21%)\n",
        "3. Sepertinya terdapat kolom yang bisa ditindak lanjut : `experience`, `company_size`, dan `last_new_job`\n",
        "\n",
        "B. Pengamatan describe:\n",
        "1. Tidak ada issue pada nilai minimal dan maksimal untuk semua kolom\n",
        "2. Kolom `city_development_index` tampaknya skew ke kiri (long-left tail)\n",
        "3. Kolom `training_hours` tampaknya skew ke kanan (long-right tail)\n",
        "4. Data dinominasi (proporsi lebih dari 50% dari jumlah baris data) oleh kaum laki-laki (`gener`), berpengalaman (`relevent_experience`), no enrollment(`enrolled_university`), graduate(`eduction level`), dan STEM(`major_discipline`) \n",
        "5. Kolom `city` dan `experience` memiliki kardinalitas (jumlah unique values) yang cukup tinggi (123 dan 22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47g6CysDQ-ed"
      },
      "source": [
        "#### About Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7jgcup6LHNx"
      },
      "source": [
        "##### Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebuMJF0fRFx5"
      },
      "outputs": [],
      "source": [
        "# def data_explore(dataframe):\n",
        "#     print(\"DATA EXPLORATION\")\n",
        "#     print('*'*80)\n",
        "#     print(\"Shape of dataset : \",dataframe.shape)\n",
        "#     print('*'*80)\n",
        "#     print(dataframe.info())\n",
        "#     print('*'*80)\n",
        "#     print(\"STATISTICAL ANALYSIS OF NUMERICAL DATA\")\n",
        "#     print('*'*80)\n",
        "#     print(dataframe.describe().T)\n",
        "#     print('*'*80)\n",
        "#     print(\"STATISTICAL ANALYSIS OF CATEGORICAL DATA\")\n",
        "#     print('*'*80)\n",
        "#     print(dataframe.describe(exclude = ['float', 'int64']).T)\n",
        "#     print('*'*80)\n",
        "#     print(\"MISSING VALUES\")\n",
        "#     print('*'*80)\n",
        "#     print(dataframe.isna().sum().sort_values(ascending=False))\n",
        "#     print('*'*80)\n",
        "#     print(\"MISSING VALUES IN %\")\n",
        "#     print('*'*80)\n",
        "#     print(round(100* (dataframe.isnull().sum() / len(dataframe)).sort_values(ascending=False),2))\n",
        "#     print('*'*80)\n",
        "    \n",
        "# data_explore(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNdBPMWpLTEa"
      },
      "source": [
        "##### Value Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAKCo6s6LYBG"
      },
      "source": [
        "Kita dapat memastikan pengamatan mengenai kolom-kolom categorical di atas dengan value counting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm08q_OULZt5"
      },
      "outputs": [],
      "source": [
        "# nums = ['enrollee_id','city_development_index', 'training_hours', 'target']\n",
        "# cats = ['city','gender','relevent_experience','enrolled_university','education_level','major_discipline','experience','company_size','company_type','last_new_job']\n",
        "# for col in cats:\n",
        "#     print(f'''Value count kolom {col}:''')\n",
        "#     print(test[col].value_counts())\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLjbUDUipv-o"
      },
      "source": [
        "Kesimpulan tentang test data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBt_GAtMQ-rq"
      },
      "source": [
        "#### About Test Answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLmSMJAHRGMZ"
      },
      "outputs": [],
      "source": [
        "# Check info\n",
        "#ss.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf3CnhmXMFpj"
      },
      "outputs": [],
      "source": [
        "# Check total number of Null Data\n",
        "#ss.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyTM5POUMFQv"
      },
      "outputs": [],
      "source": [
        "# Check describe\n",
        "# ss.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EkoO6hAimNW"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYzYGrjkMe6b"
      },
      "source": [
        "##### Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8riPY0-GMkCu"
      },
      "source": [
        "Setelah melakukan analisis sederhana tentang statistik deskriptif, sekarang kita fokus pada satu-persatu kolom dengan *Univariate Analysis*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4DngbyNJBc"
      },
      "source": [
        "###### Numerical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz2K5p_qNb6-"
      },
      "source": [
        "**Boxplot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDLtOgoDi2rd"
      },
      "outputs": [],
      "source": [
        "features = nums\n",
        "for i in range(0, len(features)):\n",
        "    plt.subplot(1, len(features), i+1)\n",
        "    sns.boxplot(y=train[features[i]], color='green', orient='v')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2JakaFgNtoq"
      },
      "source": [
        "**Hasil Pengamatan:**\n",
        "\n",
        "Untuk boxplot, hal paling penting yang harus kita perhatikan adalah keberadaan outlier.\n",
        "* Outlier yang sangat tipis pada kolom `city_development_index`\n",
        "* Dari boxplotnya juga tampak mana distribusi yang terlihat *skewed*: `city_development_index` (kiri) dan `training_hours` (kanan)\n",
        "* Diketahui kolom target bertipe boolean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O11SgpFUN0sn"
      },
      "source": [
        "**Dist Plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeNw5-XbN8Oh"
      },
      "outputs": [],
      "source": [
        "features = nums\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i in range(0, len(features)):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    sns.kdeplot(x=train[features[i]], color='green')\n",
        "    plt.xlabel(features[i])\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9o7jANIOK9y"
      },
      "source": [
        "**Violin Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2uHNLYjONJs"
      },
      "outputs": [],
      "source": [
        "features = nums\n",
        "for i in range(0, len(features)):\n",
        "    plt.subplot(1, len(features), i+1)\n",
        "    sns.violinplot(y=train[features[i]], color='gray', orient='v')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiHDkJ6wOZoI"
      },
      "source": [
        "**Hasil Pengamatan:**\n",
        "\n",
        "Untuk distribution plot, hal utama yang perlu diperhatikan adalah bentuk distribusi:\n",
        "* Seperti dugaan kita ketika melihat boxplot dan violin di atas, kedua kolom *skewed* (`city_development_index` (skewed kiri) dan `training_hours` (skewed kanan))\n",
        "* Berarti ada kemungkinan kita perlu melakukan sesuatu pada kedua kolom tersebut nantinya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-a5f6r0O5sh"
      },
      "source": [
        "###### Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1sRp9SmPBbM"
      },
      "outputs": [],
      "source": [
        "train_sample = train.sample(2500, random_state=42)\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(0, len(cats)):\n",
        "    plt.subplot(5, 2, i+1)\n",
        "    sns.countplot(y = train_sample[cats[i]], color='green', orient='v')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNfL2eiDPVtN"
      },
      "source": [
        "**Hasil Pengamatan:**\n",
        "\n",
        "1. kolom (`enrollee_id`) merupakan primary keys sehingga distribusi plot sangat luas dan dapat kita lakukan drop untuk kolom ini <br>\n",
        "2. kolom (`target`) merupakan data boelan dan imbalance <br>\n",
        "3. Kandidat didominasi oleh Male (`Gender`), STEM (`major_dicipline`) dan Pvt Ltd (`company_size`) <br>\n",
        "4. kolom (`city_development_index`) memiliki distribusi yang skew ke kiri sedangkan kolom (`training_hours`) memiliki distribusi skew yang extrem ke kanan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTkZiHKBPhRF"
      },
      "source": [
        "#### Multivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIUTo8wuP5zS"
      },
      "source": [
        "##### Numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqj0gschP0br"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(train.drop('enrollee_id', axis=1).corr(), cmap='viridis', annot=True, fmt='.2f')\n",
        "sns.pairplot(train_sample, diag_kind ='kde', hue='target');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5qeY7JQQK02"
      },
      "source": [
        "**Hasil Pengamatan**\n",
        "\n",
        "1. Berdasarkan heatmap plot, `trainning hours` tidak memiliki impact yang sangat signifikan terhadap target <br>\n",
        "2. `City_development_index` berkorelasi negatif terhadap nilai targetnya dan memiliki nilai korelasi lemah dengan target <br>\n",
        "3. Dari pairplot, terlihat bahwa persebaran target yang searching for new job cukup merata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZJ_EgouQpMi"
      },
      "source": [
        "**1. Bagaimana pengaruh City Development Index ketika seseorang memutuskan mencari pekerjaan baru?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwId-9DiQufs"
      },
      "outputs": [],
      "source": [
        "g = sns.kdeplot(train['city_development_index'][(train[\"target\"] == 0) & (train['city_development_index'].notnull())], color=\"Red\", shade = True)\n",
        "g = sns.kdeplot(train['city_development_index'][(train[\"target\"] == 1) & (train['city_development_index'].notnull())], ax =g, color=\"Grey\", shade= True)\n",
        "g.set_xlabel('city_development_index')\n",
        "g.set_ylabel(\"Frequency\")\n",
        "g.set_title('Does the City Development Index play a role?')\n",
        "plt.ylim(0, 15)\n",
        "g = g.legend([\"Not looking for job change\",\"looking for job change\"], loc='upper left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqUm2Xn1RNG9"
      },
      "source": [
        "Pengamatan :\n",
        "1. Kandidat dengan CDI rendah (0,66) cenderung memiliki keinginan untuk mencari pekerjaan baru\n",
        "2. Kandidat dengan CDI tinggi (0.9) cenderung sangat tidak tertarik mencari pekerjaan baru."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSz4IE5hRffe"
      },
      "source": [
        "**2. Bagaimana pengaruh Training Hours dengan keinginan seseorang untuk mencari pekerjaan baru?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v9c06teR4pB"
      },
      "outputs": [],
      "source": [
        "g = sns.kdeplot(train['training_hours'], hue='target',data=train, color=\"Red\", shade = True)\n",
        "g.set_xlabel('training_hours')\n",
        "g.set_ylabel(\"Frequency\")\n",
        "g.legend([\"Not looking for job change,\",\"looking for job change,\"])\n",
        "g.set_title('Does Training Hours matter?', fontsize=15, fontweight='bold', fontfamily='serif', color=\"#323232\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq3ddepTR4KP"
      },
      "source": [
        "Pengamatan :\n",
        "1. Kandidat dengan training hours kurang lebih 20 jam memiliki kecenderungan untuk mencari pekerjaan baru\n",
        "2. Dapat dilihat jumlah waktu course yang diikuti kandidat adalah sekitar 46-48 jam.\n",
        "3. Semakin banyak jumlah training hours maka semakin sedikit kecenderungan untuk mencari pekerjaan baru "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eukUr_0wP7Ep"
      },
      "source": [
        "##### Categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blueis = ['#1F4E5F','#79A8A9','#AACFD0','#fbfbfb']\n",
        "sns.set_palette(blueis)\n",
        "sns.palplot(sns.color_palette())"
      ],
      "metadata": {
        "id": "llcItUCY4_Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('jumlah target 1 = ', train[train['target']==1].target.count(), ' orang')\n",
        "sns.countplot(x=train['target'], palette=blueis);"
      ],
      "metadata": {
        "id": "tuPNptGP5CnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['target']==1]['last_new_job'].value_counts()"
      ],
      "metadata": {
        "id": "u4NeyV7A5NLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsVqA6S2SWfW"
      },
      "outputs": [],
      "source": [
        "values = {}\n",
        "lists =[]\n",
        "for col in cats:\n",
        "    plt.figure(figsize=(12,4), dpi =80)\n",
        "    ax = sns.countplot(data=train,x=col, palette=sns.color_palette(),hue = 'target')\n",
        "    plt.xlabel(col, family='serif', fontsize=13)\n",
        "    plt.xticks(family='serif')\n",
        "    plt.ylabel('Count', family='serif', fontsize=13)\n",
        "    plt.xticks(family='serif')\n",
        "    plt.legend(('Non Job-Seeker', 'Job-Seeker'), prop={'family': 'serif', 'size': 8})\n",
        "    a = list()\n",
        "    b = list()\n",
        "    numbers = 0\n",
        "    n = len(ax.patches)\n",
        "    for p in ax.patches:\n",
        "        if numbers < n/2: a.append(p.get_height())\n",
        "        else: b.append(p.get_height())\n",
        "        numbers += 1\n",
        "    if col == 'gender':\n",
        "        print(a)\n",
        "        print(b)\n",
        "    a = sum(a)\n",
        "    b = sum(b)\n",
        "    numbers = 0\n",
        "    for p in ax.patches:\n",
        "        if numbers < n/2: h = round(100*p.get_height()/a,2)\n",
        "        else: h = round(100*p.get_height()/b,2)\n",
        "        height=str(h)+'%'\n",
        "        background_color= '#fbfbfb'\n",
        "        ax.annotate(height, (p.get_x()+p.get_width()/2, p.get_height()*1.01), ha='center',fontfamily='serif', fontsize= 10)\n",
        "        lists.append(p.get_height())\n",
        "        numbers += 1\n",
        "    values[col]=lists\n",
        "    lists=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVs-BaijSkYM"
      },
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "Dari hasil multivariate analysis, terlihat bahwa presentase yang tidak mencari pekerjaan (target=0) lebih banyak dibandingkan dengan yang mencari pekerjaan (target=1) disetiap featurenya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM4Ett2giTrP"
      },
      "source": [
        "### Insights and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=train.groupby(['target'])['target'].count()\n",
        "y=len(train)\n",
        "r=((x/y)).round(2)\n",
        "ratio = pd.DataFrame(r).T\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(6.5, 2),dpi=150)\n",
        "background_color = '#fbfbfb'\n",
        "fig.patch.set_facecolor(background_color)\n",
        "ax.set_facecolor(background_color) \n",
        "\n",
        "ax.barh(ratio.index, ratio[0.0], color='#79A8A9', alpha=0.9, ec=background_color, label='Job-Seeker')\n",
        "ax.barh(ratio.index, ratio[1.0], left=ratio[0.0], color='#1F4E5F', alpha=0.9,ec=background_color, label='Non Job-Seeker')\n",
        "\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.legend().set_visible(False)\n",
        "for s in ['top', 'left', 'right', 'bottom']:\n",
        "    ax.spines[s].set_visible(False)\n",
        "\n",
        "for i in ratio.index:\n",
        "    ax.annotate(f\"{int(ratio[0.0][i]*100)}%\", xy=(ratio[0.0][i]/2, i),va = 'center', ha='center',fontsize=32, fontweight='light', fontfamily='serif',color='white')\n",
        "    ax.annotate(\"Non Job-Seeker\", xy=(ratio[0.0][i]/2, -0.25),va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='serif',color='white')\n",
        "\n",
        "for i in ratio.index:\n",
        "    ax.annotate(f\"{int(ratio[1.0][i]*100)}%\", xy=(ratio[0.0][i]+ratio[1.0][i]/2, i),va = 'center', ha='center',fontsize=32, fontweight='light', fontfamily='serif',color='white')\n",
        "    ax.annotate(\"Job-Seeker\", xy=(ratio[0.0][i]+ratio[1.0][i]/2, -0.25),va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='serif',color='white')\n",
        "\n",
        " \n",
        "fig.text(0.125,1.1,'Berapa banyak yang mencari pekerjaan?', fontfamily='serif',fontsize=15, fontweight='bold', color='#1F4E5F')\n",
        "fig.text(0.125,0.915,'We have imbalance data\\nKandidat didominasi oleh Non Job-Seeker',fontfamily='serif',fontsize=10)  \n",
        "\n",
        "# fig1 = plt.gcf()\n",
        "# plt.savefig('job-seeker%.png', bbox_inches='tight',dpi=500)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Bw-JuD76LUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_palette=[\"gray\",\"#0e4f66\"]\n",
        "fig = plt.figure(figsize=(20,15), dpi=150)\n",
        "fig.patch.set_facecolor(background_color) # figure background color\n",
        "gs = fig.add_gridspec(3, 3)\n",
        "gs.update(wspace=0.4, hspace=0.8)\n",
        "ax0 = fig.add_subplot(gs[0, 0])\n",
        "ax1 = fig.add_subplot(gs[0, 1])\n",
        "ax2 = fig.add_subplot(gs[1, 0])\n",
        "ax3 = fig.add_subplot(gs[1, 1])\n",
        "ax4 = fig.add_subplot(gs[2, 0])\n",
        "ax5 = fig.add_subplot(gs[2, 1])\n",
        "ax6 = fig.add_subplot(gs[0, 2])\n",
        "\n",
        "# Gender\n",
        "ax0.text(-0.7, 4700, 'Siapa saja yang sedang mencari pekerjaan?', fontsize=20, fontweight='bold', fontfamily='serif')\n",
        "ax0.text(-0.7, 4200, 'Overall', fontsize=16, fontweight='bold', fontfamily='serif')\n",
        "ax0.text(-0.7, 3400, 'Job searching by gender', fontsize=14, fontweight='bold', fontfamily='serif')\n",
        "sns.countplot(x=\"gender\", data=train[train['target']==1], palette=blueis, ax=ax0, zorder=3)\n",
        "\n",
        "# Major Discipline\n",
        "ax1.text(-1, -1, 'Job searching by major discipline', fontsize=14, fontweight='bold', fontfamily='serif', color=\"#323232\")\n",
        "sns.countplot(y=\"major_discipline\",hue='target', data=train, orient='v', palette=color_palette, ax=ax1, zorder=3)\n",
        "legend_labels, _= ax1.get_legend_handles_labels()\n",
        "ax1.legend(legend_labels, [\"Non-Job Seeker\", \"Job Seeker\"], ncol=2, bbox_to_anchor=(0.8, 1.28), facecolor=background_color, edgecolor=background_color)\n",
        "\n",
        "#Relevant Experience\n",
        "ax6.text(-0.5, 3400, 'Job searching by relevent experience', fontsize=14, fontweight='bold', fontfamily='serif', color=\"#323232\")\n",
        "sns.countplot(x=\"relevent_experience\", data=train[train['target']==1], palette=blueis, ax=ax6, zorder=3)\n",
        "\n",
        "# CDI\n",
        "ax2.text(0.3, 19, 'Bagaimana pengaruh City Development Index dan Training Hours?', fontsize=20, fontweight='bold', fontfamily='serif', color=\"#323232\")\n",
        "ax2.text(0.3, 17.5, 'Menariknya, Job Seekers cukup banyak berasal dari kota dengan skor CDI rendah', fontsize=14, fontweight='light', fontfamily='serif', color=\"#323232\")\n",
        "ax2.text(0.3, 16, 'Job searching by CDI', fontsize=14, fontweight='bold', fontfamily='serif', color=\"#323232\")\n",
        "sns.kdeplot(train.loc[(train[\"target\"]==0), \"city_development_index\"], color='#79A8A9', shade = True, alpha= 0.6,label=\"Not Survived\", ax=ax2)\n",
        "sns.kdeplot(train.loc[(train[\"target\"]==1), \"city_development_index\"], color=\"Red\", shade = True, label=\"Survived\", ax=ax2)\n",
        "\n",
        "#Training Hours\n",
        "ax3.text(-100, 0.013, 'Job searching by Training Hours', fontsize=14, fontweight='bold', fontfamily='serif', color=\"#323232\")\n",
        "sns.kdeplot(train.loc[(train[\"target\"]==0), \"training_hours\"], color=\"#79A8A9\",shade= True, label=\"Not Survived\", ax=ax3)\n",
        "sns.kdeplot(train.loc[(train[\"target\"]==1), \"training_hours\"], color=\"red\", shade= True, label=\"Survived\", ax=ax3)\n",
        "legend_labels, _= ax3.get_legend_handles_labels()\n",
        "ax3.legend(legend_labels, [\"Non-Job Seeker\", \"Job Seeker\"], ncol=2, bbox_to_anchor=(0.1, -0.1), facecolor=background_color, edgecolor=background_color)\n",
        "\n",
        "\n",
        "###\n",
        "train['count'] = 1\n",
        "job_hunt_only = train[train['target']==1]\n",
        "no_job_hunt_only = train[train['target']==0]\n",
        "\n",
        "job_change = train.groupby(['education_level','last_new_job'])['experience'].sum().unstack()\n",
        "\n",
        "job_hunt_only.groupby(['target','last_new_job'])['count'].sum().unstack()\n",
        "notseek_job_change = no_job_hunt_only.groupby(['target','last_new_job'])['count'].sum().unstack().T\n",
        "seek_job_change = job_hunt_only.groupby(['target','last_new_job'])['count'].sum().unstack().T\n",
        "\n",
        "notseek_job_change.columns = ['count']\n",
        "seek_job_change.columns = ['count']\n",
        "\n",
        "notseek_job_change[\"percentage\"] = notseek_job_change[\"count\"].apply(lambda x: x/sum(notseek_job_change[\"count\"])) *100\n",
        "seek_job_change[\"percentage\"] = seek_job_change[\"count\"].apply(lambda x: x/sum(seek_job_change[\"count\"])) *100\n",
        "\n",
        "\n",
        "ed_notseek_job_change = no_job_hunt_only.groupby(['target','education_level'])['count'].sum().unstack().T\n",
        "ed_seek_job_change = job_hunt_only.groupby(['target','education_level'])['count'].sum().unstack().T\n",
        "\n",
        "ed_notseek_job_change.columns = ['count']\n",
        "ed_seek_job_change.columns = ['count']\n",
        "\n",
        "ed_notseek_job_change[\"percentage\"] = ed_notseek_job_change[\"count\"].apply(lambda x: x/sum(ed_notseek_job_change[\"count\"])) *100\n",
        "ed_seek_job_change[\"percentage\"] = ed_seek_job_change[\"count\"].apply(lambda x: x/sum(ed_seek_job_change[\"count\"])) *100\n",
        "\n",
        "###\n",
        "ax4.barh(notseek_job_change.index, notseek_job_change['percentage'], color=\"gray\", zorder=3, height=0.7)\n",
        "ax4.barh(seek_job_change.index, seek_job_change['percentage'], color=\"#1F4E5F\", zorder=3, height=0.3)\n",
        "ax4.xaxis.set_major_locator(mtick.MultipleLocator(10))\n",
        "\n",
        "##\n",
        "ax5.barh(ed_notseek_job_change.index, ed_notseek_job_change['percentage'], color=\"gray\", zorder=3, height=0.7)\n",
        "ax5.barh(ed_seek_job_change.index, ed_seek_job_change['percentage'], color=\"#1F4E5F\", zorder=3, height=0.3)\n",
        "ax5.xaxis.set_major_locator(mtick.MultipleLocator(10))\n",
        "\n",
        "##\n",
        "ax4.text(-2.5, 5.75, 'Job searching by Last job change (yrs)',fontsize=15, fontweight='bold', fontfamily='serif',color='#323232')\n",
        "ax5.text(0, 4.55, 'Job searching by Education level', fontsize=15, fontweight='bold', fontfamily='serif',color='#323232')\n",
        "\n",
        "ax4.text(-2.5, 7.2, 'Bagaimana dengan pekerjaan sebelumnya dan level pendidikannya?', \n",
        "         fontsize=20, fontweight='bold', fontfamily='serif',color='#323232')\n",
        "\n",
        "ax4.text(-2.5, 6.5, \n",
        "         'Kandidat dengan pengalaman kurang dari 1 tahun dan lulusan sarjana adalah job seeker terbanyak', \n",
        "         fontsize=14, fontweight='light', fontfamily='serif')\n",
        "\n",
        "\n",
        "####\n",
        "\n",
        "fig.text(0.72, 0.63\n",
        "         , 'Insight', fontsize=16, fontweight='bold', fontfamily='serif',color='#323232')\n",
        "\n",
        "fig.text(0.72, 0.04, '''\n",
        "Data dinominasi (proporsi lebih dari 50% data) \n",
        "olehkaum laki-laki, berpengalaman dan STEM.\n",
        "88.90% job-seeker adalah laki-laki dan\n",
        "hanya 9.62% merupakan job-seeker perempuan.\n",
        "Sebanyak 89.98% berlatar pendidikan STEM \n",
        "dan 61.98% memiliki pengalaman yang relevan\n",
        "\n",
        "\n",
        "Grafik City Development Index (CDI).\n",
        "Terdapat dua puncak pada grafik job-seeker. \n",
        "Puncak dengan CDI rendah(0.6) dan CDI tinggi(0.9). \n",
        "\n",
        "Dapat kita sumsikan bahwa;\n",
        "Job seeker dengan CDI tertinggiterdorong untuk \n",
        "mencari peran baru menjadi data scientist.\n",
        "Sedangkan, job seeker dengan CDI rendah\n",
        "berharap untuk meningkatkan kualitas hidup\n",
        "mereka melalui pekerjaan baru menjadi DS.\n",
        "\n",
        "Semua ini hanya duguan tetapi \n",
        "menarik untuk diperhatikan\n",
        "\n",
        "Berbeda dengan grafik training hours;\n",
        "Ternyata tidak terdapat perbedaan dalam \n",
        "jumlah training hours antara job-seeker\n",
        "dan non job-seeker yaitu 46-48 jam.\n",
        "\n",
        "Hal yang menarik dari grafik last new job;\n",
        "Kandidat yang memiliki perbedaan 1 tahun antara \n",
        "pekerjaan lama dan pekerjaannya sekarang \n",
        "cenderung akan mencari pekerjaan baru (45.97%) \n",
        "dan kandidat yang belum pernah mencari \n",
        "ekerjaan (15.99%) tampaknya siap \n",
        "untuk tantangan baru.\n",
        "\n",
        "Grafik education level, bila dibandingkan\n",
        "dengan education level lainnya terlihat bahwa \n",
        "job-seeker dengan lulusan sarjana (69.44%) \n",
        "lebih banyak daripada non job-seeker (59,56%).\n",
        "'''\n",
        "         , fontsize=14, fontweight='light', fontfamily='serif',color='#323232')\n",
        "\n",
        "\n",
        "\n",
        "l1 = lines.Line2D([0.7, 0.7], [0.03, 0.65], transform=fig.transFigure, figure=fig,color='black',lw=0.2)\n",
        "fig.lines.extend([l1])\n",
        "\n",
        "for s in [\"top\",\"right\",\"left\"]:\n",
        "    for i in range(0,7):\n",
        "        locals()[\"ax\"+str(i)].spines[s].set_visible(False)\n",
        "        \n",
        "for i in range(0,7):\n",
        "        locals()[\"ax\"+str(i)].set_facecolor(background_color)\n",
        "        locals()[\"ax\"+str(i)].tick_params(axis=u'both', which=u'both',length=0)\n",
        "        locals()[\"ax\"+str(i)].grid(color='gray', linestyle=':', axis='y', zorder=0,  dashes=(1,5))      \n",
        "\n",
        "        \n",
        "for x in range(0,7):\n",
        "    for y in range(0,7):\n",
        "        locals()[\"ax\"+str(x)].set_xlabel(\"\")\n",
        "        locals()[\"ax\"+str(y)].set_ylabel(\"\")\n",
        "\n",
        "# fig1 = plt.gcf()\n",
        "\n",
        "# plt.savefig('insight.png', bbox_inches='tight', dpi=1500)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "LJi7WX176QaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ed_order = ['Primary School','High School','Graduate','Masters','Phd']\n",
        "# company_order = ['Pvt Ltd','Public Sector','Funded Startup','Early Stage Startup','NGO','Other']\n",
        "# enrolled_order = ['no_enrollment', 'Part time course', 'Full time course']\n",
        "\n",
        "# job_hunt_only = train[train['target']==1]\n",
        "\n",
        "# job_seek_company = pd.crosstab(job_hunt_only['education_level'],job_hunt_only['company_type'], normalize='index').loc[ed_order,company_order]\n",
        "# job_seek_enrolled = pd.crosstab(job_hunt_only['education_level'],job_hunt_only['enrolled_university'], normalize='index').loc[ed_order,enrolled_order]\n",
        "\n",
        "# fig = plt.figure(figsize=(10,4),dpi=150)\n",
        "# fig.patch.set_facecolor(background_color)\n",
        "\n",
        "# gs = fig.add_gridspec(1, 2)\n",
        "# gs.update(wspace=0.05, hspace=0.1)\n",
        "# ax0 = fig.add_subplot(gs[0,0])\n",
        "# ax1 = fig.add_subplot(gs[0,1])\n",
        "\n",
        "\n",
        "# colors = ['gray', '#AACFD0', '#1F4E5F']\n",
        "# colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
        "\n",
        "# sns.heatmap(ax=ax0, data=job_seek_company, linewidths=.1, vmin=-0, vmax=1,\n",
        "#            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False, cmap=colormap,linewidth=3, annot=True, fmt='1.0%',annot_kws={\"fontsize\":14})\n",
        "\n",
        "# sns.heatmap(ax=ax1, data=job_seek_enrolled, linewidths=.1, vmin=-0, vmax=1, cbar_kws={\"orientation\": \"horizontal\"},\n",
        "#            cbar=False, cmap=colormap,yticklabels=False,linewidth=3,annot=True, fmt='1.0%',annot_kws={\"fontsize\":14})\n",
        "\n",
        "\n",
        "# ax0.set_facecolor(background_color)\n",
        "# ax1.set_facecolor(background_color) \n",
        "# ax0.set_xlabel(\"\")\n",
        "# ax0.set_ylabel(\"\")\n",
        "\n",
        "# for s in [\"top\",\"right\",\"left\"]:\n",
        "#     ax0.spines[s].set_visible(False)\n",
        "\n",
        "\n",
        "# ax1.set_xlabel(\"\")\n",
        "# ax1.set_ylabel(\"\")\n",
        "\n",
        "# for s in [\"top\",\"right\",\"left\"]:\n",
        "#     ax0.spines[s].set_visible(False)\n",
        "#     ax1.spines[s].set_visible(False)\n",
        "    \n",
        "    \n",
        "# ax0.text(0, -0.6, \n",
        "#          'Education level &\\nCompany type', \n",
        "#          fontsize=20, \n",
        "#          fontweight='bold', \n",
        "#          fontfamily='serif',\n",
        "#         )\n",
        "\n",
        "# ax0.text(0, -0.08, \n",
        "#          '    ', \n",
        "#          fontsize=13, \n",
        "#          fontweight='light', \n",
        "#          fontfamily='serif',\n",
        "#         )\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "# ax1.text(0, -0.6, \n",
        "#          'Education level &\\nEnrolled university', \n",
        "#          fontsize=20, \n",
        "#          fontweight='bold', \n",
        "#          fontfamily='serif',\n",
        "#         )\n",
        "# ax1.text(0, -0.2, \n",
        "#          '    ', \n",
        "#          fontsize=13, \n",
        "#          fontweight='light', \n",
        "#          fontfamily='serif',\n",
        "#         )\n",
        "    \n",
        "\n",
        "# ax0.tick_params(axis=u'both', which=u'both',length=0)\n",
        "# ax1.tick_params(axis=u'both', which=u'both',length=0)\n",
        "\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "2_w3dJjw7KXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RIdr6LAS4_R"
      },
      "source": [
        "Dari EDA di atas, didapatkan beberapa bussiness insight :\n",
        "\n",
        "1. City Development Index : \n",
        "      1. Kandidat dengan CDI rendah (0,66) cenderung memiliki keinginan untuk mencari pekerjaan baru\n",
        "      2. Kandidat dengan CDI tinggi (0.9) cenderung sangat tidak tertarik mencari pekerjaan baru.\n",
        "\n",
        "\n",
        "2. Training Hours :\n",
        "     1. Kandidat dengan training hours kurang lebih 20 jam memiliki kecenderungan untuk mencari pekerjaan baru\n",
        "     2. Dapat dilihat jumlah waktu course yang diikuti kandidat adalah sekitar 46-48 jam.\n",
        "     3. Semakin banyak jumlah training hours maka semakin sedikit kecenderungan untuk mencari pekerjaan baru \n",
        "      \n",
        "      \n",
        "3. Gender :\n",
        "      1. 88.9% kandidat laki-laki cenderung mencari pekerjaan baru.\n",
        "      2. Hanya 9.62% kandidat perempuan yang cenderung akan mencari pekerjaan baru.\n",
        "\n",
        "\n",
        "4. Company Type : \n",
        "      * Kandidat dari Company Type Pvt Ltd paling banyak ingin mencari pekerjaan baru, yaitu sebesar 74.17%.\n",
        "\n",
        "\n",
        "5. Education Level :\n",
        "      * Kandidat dengan education level graduate paling banyak mencari pekerjaan baru yaitu sebesar 69.44%   \n",
        "\n",
        "\n",
        "6. Major Discipline :\n",
        "      * Kandidat dengan Major discipline STEM (Science Technology Engineering Math) paling banyak mencari pekerjaan baru yaitu sebesar 89.66%.\n",
        "\n",
        "\n",
        "7. Relevant Experience :\n",
        "      1. 61.98% kandidat dengan relevant experience cenderung akan mencari pekerjaan baru. \n",
        "      2. 38.02% kandidat dengan non-relevant experience cenderung akan mencari pekerjaan baru.\n",
        "\n",
        " \n",
        "8. Experience - kandidat yang cenderung akan mencari pekerjaan baru adalah kandidat dengan total experience:\n",
        "      1. Di atas 20 tahun experience (10.58%)\n",
        "      2. 3 tahun experience(9.61%)\n",
        "      3. 4 tahun experience(10.05%)\n",
        "\n",
        "\n",
        "9. Last New Job :\n",
        "    * Kandidat yang memiliki perbedaan 1 tahun antara pekerjaan lama dan pekerjaannya sekarang cenderung akan mencari pekerjaan baru (45.97%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBDt43spi8a-"
      },
      "source": [
        "## <b>STAGE 2. DATA PREPROCESSING</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleansing\n",
        "1. Handle missing values\n",
        "2. Handle duplicated data\n",
        "3. Handle outliers\n",
        "4. Feature transformation w\n",
        "5. Feature encoding\n",
        "6. Handle class imbalance w"
      ],
      "metadata": {
        "id": "UKBbnmc0uiL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing = 100 * train.isna().sum().sort_values(ascending=False) / train.shape[0]\n",
        "missing.plot(kind='bar', color=\"mediumspringgreen\", figsize=(17,8))\n",
        "plt.title(\"\\nPercentages of Missing Values\\n\\n\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VPGn13NSIbmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "WgEv-Kx3IzhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handle Duplicated Data\n",
        "\n",
        "Pada tahap ini dilakukan pengecekan dan drop baris apabila terdapat data yang terduplikasi.\n",
        "\n"
      ],
      "metadata": {
        "id": "JGYkNwZaaFkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfc = train.copy()\n",
        "# Drop duplicated rows\n",
        "print(f'Jumlah row duplicated sebelum dihapus: {dfc.duplicated().sum()}')\n",
        "dfc.drop_duplicates(inplace=True)\n",
        "print(f'Jumlah row duplicated SETELAH dihapus: {dfc.duplicated().sum()}')\n",
        "\n",
        "dfc.drop(['enrollee_id','training_hours'], 1, inplace=True)\n",
        "dfc.shape"
      ],
      "metadata": {
        "id": "SWHsBbaOomIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature `training_hours` perlu di drop karena berdasarkan heatmap plot pada tahap EDA sebelumnya, feature ini memiliki korelasi yang sangat kecil dengan kolom `target`.\n"
      ],
      "metadata": {
        "id": "h1XxMa-1m5aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Encoding\n",
        "\n",
        "Untuk mempermudah proses pemodelan, maka value data perlu diubah menjadi numerik dengan metode Label Encoder."
      ],
      "metadata": {
        "id": "rkAWO5SDcnNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfc['company_size'] = dfc['company_size'].replace(10/49, '10-49')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "to_LabelEncode = dfc[['city','gender', 'relevent_experience',\n",
        "       'enrolled_university', 'education_level', 'major_discipline',\n",
        "       'experience', 'company_size', 'company_type', 'last_new_job']]\n",
        "\n",
        "le = LabelEncoder()\n",
        "dfc_temp = to_LabelEncode.astype(\"str\").apply(le.fit_transform)\n",
        "display(dfc_temp)\n",
        "# I don't want NaN values is categorized as a new label\n",
        "dfc_final = dfc_temp.where(~to_LabelEncode.isna(), to_LabelEncode)\n",
        "display(dfc_final)\n",
        "\n",
        "dff = dfc.copy()\n",
        "dff = dff.drop(['city','gender', 'relevent_experience','enrolled_university', 'education_level',\n",
        "                'major_discipline','experience', 'company_size', 'company_type', 'last_new_job'], axis = 1)\n",
        "dff = dfc_final.join(dff)\n",
        "display(dff)"
      ],
      "metadata": {
        "id": "XuRky7rsfTR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handle Missing Values\n",
        "Handle missing values in the dataset:\n",
        "- Deleting Rows with missing values\n",
        "> Pros:<br>\n",
        "A model trained with the removal of all missing values creates a robust model.<br>\n",
        "Cons:<br>\n",
        "Loss of a lot of information.\n",
        "Works poorly if the percentage of missing values is excessive in comparison to the complete dataset.\n",
        "- Impute missing values for continuous variable (Mean/Median)\n",
        "> Pros:<BR>\n",
        "Prevent data loss which results in deletion of rows or columns.\n",
        "Works well with a small dataset and is easy to implement.<Br>\n",
        "Cons:<Br>\n",
        "Works only with numerical continuous variables.\n",
        "Can cause data leakage.\n",
        "Do not factor the covariance between features.<br>\n",
        "- Impute missing values for categorical variable (Modus)\n",
        "> Pros:<Br>\n",
        "Prevent data loss which results in deletion of rows or columns.\n",
        "Works well with a small dataset and is easy to implement.\n",
        "Negates the loss of data by adding a unique category<Br>\n",
        "Cons:<Br>\n",
        "Works only with categorical variables.\n",
        "Addition of new features to the model while encoding, which may result in poor performance<br>\n",
        "- Other Imputation Methods\n",
        "> LOCF, BOCF, LRCF dan NOCB\n",
        "- Using Algorithms that support missing values (The k-NN algorithm, Naive Bayes, RandomForest)\n",
        "> Pros:<br>\n",
        "No need to handle missing values in each column as ML algorithms will handle them efficiently.<Br>\n",
        "Cons:<Br>\n",
        "No implementation of these ML algorithms in the scikit-learn library.<br>\n",
        "- Prediction of missing values\n",
        "> Pros:<br>\n",
        "Gives a better result than earlier methods\n",
        "Takes into account the covariance between the missing value column and other columns.<Br>\n",
        "Cons:<Br>\n",
        "Considered only as a proxy for the true values\n",
        "- Imputation using Deep Learning Library — Datawig\n",
        "> Pros:<br>\n",
        "Quite accurate compared to other methods.\n",
        "It supports CPUs and GPUs.<Br>\n",
        "Cons:<Br>\n",
        "Can be quite slow with large datasets.\n",
        "\n",
        "source : https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e <Br>\n",
        "http://onbiostatistics.blogspot.com/2021/01/single-imputation-methods-for-missing.html"
      ],
      "metadata": {
        "id": "e1a7yo-QvCVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('*'*80)\n",
        "print(\"MISSING VALUES\")\n",
        "print('*'*80)\n",
        "print(train.isna().sum().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "hq38sCV83eS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values diisi dengan menggunakan Mice Iterative Imputer."
      ],
      "metadata": {
        "id": "uTRf-ojZtJ_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "mice_imputer = IterativeImputer(random_state=42, estimator=lr, max_iter=10, n_nearest_features=2, \n",
        "                                imputation_order = 'roman')\n",
        "final_dff = mice_imputer.fit_transform(dff)\n",
        "\n",
        "final_dff = pd.DataFrame(final_dff)\n",
        "final_dff.columns = ['city','gender', 'relevent_experience', 'enrolled_university', 'education_level', \n",
        "                     'major_discipline','experience', 'company_size', 'company_type', 'last_new_job', \n",
        "                     'city_development_index','target']\n",
        "                                                        \n",
        "display(final_dff)"
      ],
      "metadata": {
        "id": "lgV0AXocpST6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dff.isnull().sum()"
      ],
      "metadata": {
        "id": "wSEcX97VsL1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# melihat correlation heatmap barangkali ada feature lain yang kurang relevan.\n",
        "matrix = np.triu(final_dff.corr())\n",
        "plt.figure(figsize=(13, 10))\n",
        "sns.heatmap(final_dff.corr(), annot = True, fmt=\".3f\", mask = matrix,\n",
        "            vmin = -1, vmax = 1, linewidths = 0.1, linecolor = 'white', cbar = False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EqWWODQGrEKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>STAGE 3. MACHINE LEARNING MODELLING AND EVALUATION</b>"
      ],
      "metadata": {
        "id": "0xetZajTecw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Imbalance"
      ],
      "metadata": {
        "id": "eSfUwofNcl4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada dataset ini, nilai 0 pada kolom target\n",
        "memiliki jumlah yang jauh lebih banyak\n",
        "dibanding dengan nilai 1. Maka\n",
        "dari itu diperlukan pemerataan agar data tidak terlalu timpang. Teknik yang diterapkan yaitu SMOTE."
      ],
      "metadata": {
        "id": "gNgMuXDMcl4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data Train & Test\n",
        "\n",
        "X = final_dff.drop(['target'],1)\n",
        "y = final_dff.target\n",
        "\n",
        "X_train,X_test,y_train,y_test = tts(X,y,test_size=0.25, random_state=42)\n",
        "\n",
        "print('Before SMOTE')\n",
        "print('=====SHAPE=====')\n",
        "print(\"X TRAIN SHAPE: \",X_train.shape)\n",
        "print(\"X TEST SHAPE: \",X_test.shape)\n",
        "print(\"Y TRAIN SHAPE: \",y_train.shape)\n",
        "print(\"Y TEST SHAPE: \",y_test.shape)\n",
        "\n",
        "# Hasil index before SMOTE\n",
        "print('=====INDEX=====')\n",
        "print(\"TRAIN:\",X_train.index, \"\\nTEST:\",X_test.index)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "sRhyfoO2cl4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_smote = SVMSMOTE(sampling_strategy='minority', random_state=42, k_neighbors=5)\n",
        "X_svm_smote, y_svm_smote = svm_smote.fit_resample(X,y)\n",
        "\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = tts(X_svm_smote,y_svm_smote, test_size=0.25, random_state=42)\n",
        "\n",
        "print('After SMOTE')\n",
        "print('=====SHAPE=====')\n",
        "print(\"X TRAIN SHAPE: \",X_train_svm.shape)\n",
        "print(\"X TEST SHAPE: \",X_test_svm.shape)\n",
        "print(\"Y TRAIN SHAPE: \",y_train_svm.shape)\n",
        "print(\"Y TEST SHAPE: \",y_test_svm.shape)\n",
        "\n",
        "# Hasil index after SMOTE\n",
        "print('=====INDEX=====')\n",
        "print(\"TRAIN:\",X_train_svm.index, \"\\nTEST:\",X_test_svm.index)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train_svm = sc.fit_transform(X_train_svm)\n",
        "X_test_svm = sc.transform(X_test_svm)\n",
        "\n"
      ],
      "metadata": {
        "id": "B3McJB1ncl4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling and Evaluation"
      ],
      "metadata": {
        "id": "Q389DhS9FwiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    errors = abs(y_pred - y_test)\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    print(confusion_matrix(y_test,y_pred))\n",
        "    plt.figure(figsize = (5,3))\n",
        "    sns.heatmap(confusion_matrix(y_test,y_pred), annot=True, cmap = 'gist_earth')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Truth')\n",
        "    print('Accuracy Score = ',accuracy_score(y_test, y_pred))\n",
        "    print('Recall Score = ',recall_score(y_test, y_pred))\n",
        "    print('Precision Score = ',precision_score(y_test, y_pred))\n",
        "    print('F1 score = ', f1_score(y_test,y_pred))\n",
        "\n",
        "    return evaluate"
      ],
      "metadata": {
        "id": "t8cIzzCit4MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_auc_roc_curve(model, X_test, y_test, X_train, y_train):\n",
        "  base_fpr,base_tpr,base_threshold = roc_curve(y_train, model.predict(X_train))\n",
        "  plt.plot([0,1])\n",
        "  plt.plot(base_fpr,base_tpr)\n",
        "  print(\"auc score :\",auc(base_fpr,base_tpr))\n",
        "  \n",
        "\n",
        "  return train_auc_roc_curve"
      ],
      "metadata": {
        "id": "pW6GyExnt_Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritma model yang digunakan, yaitu:\n",
        "1. LogisticRegression\n",
        "2. LinearSVM\n",
        "3. rbfSVM\n",
        "4. KNearestNeighbors\n",
        "5. RandomForestClassifier\n",
        "6. DecisionTree\n",
        "7. GradientBoostingClassifier\n",
        "8. GaussianNB\n",
        "9. EasyEnsemble"
      ],
      "metadata": {
        "id": "tRQF2mq-JVjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models=[LogisticRegression(),LinearSVC(),SVC(kernel='rbf'),\n",
        "        KNeighborsClassifier(),RandomForestClassifier(),\n",
        "        DecisionTreeClassifier(),GradientBoostingClassifier(),\n",
        "        GaussianNB(),EasyEnsembleClassifier(base_estimator= LGBMClassifier(random_state=42), n_estimators=250, n_jobs=1, \n",
        "                                            random_state=42, verbose=0)]\n",
        "model_names=['LogisticRegression','LinearSVM','rbfSVM','KNearestNeighbors','RandomForestClassifier','DecisionTree',\n",
        "             'GradientBoostingClassifier','GaussianNB','EasyEnsemble']\n",
        "\n",
        "for model in range(len(models)):\n",
        "  print('\\n\\nDengan menggunakan model', models[model])\n",
        "  clf=models[model]\n",
        "  clf.fit(X_train,y_train)\n",
        "  evaluate(clf, X_test, y_test)"
      ],
      "metadata": {
        "id": "0fzsP5Tisj0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in range(len(models)):\n",
        "  print('\\n\\nDengan menggunakan model', models[model])\n",
        "  clf=models[model]\n",
        "  clf.fit(X_train,y_train)\n",
        "  train_auc_roc_curve(clf, X_test, y_test, X_train, y_train)"
      ],
      "metadata": {
        "id": "kCnvQBK63C_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in range(len(models)):\n",
        "  print('\\n\\nDengan menggunakan model', models[model])\n",
        "  clf=models[model]\n",
        "  clf.fit(X_train_svm,y_train_svm)\n",
        "  evaluate(clf, X_test_svm, y_test_svm)"
      ],
      "metadata": {
        "id": "qd79Alwk3Rrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in range(len(models)):\n",
        "  print('\\n\\nDengan menggunakan model', models[model])\n",
        "  clf=models[model]\n",
        "  clf.fit(X_train_svm,y_train_svm)\n",
        "  train_auc_roc_curve(clf, X_test_svm, y_test_svm, X_train_svm, y_train_svm)"
      ],
      "metadata": {
        "id": "bnPbJ6fV3cDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tunning"
      ],
      "metadata": {
        "id": "Q8JR3CI1Te84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "easy_lgbm = EasyEnsembleClassifier(base_estimator=LGBMClassifier(random_state=42), n_estimators=250, n_jobs=1, random_state=42, verbose = 0)\n",
        "\n",
        "param_grid = {'replacement':[True, False], 'sampling_strategy':[float, 'auto'], \n",
        "              'warm_start':[True, False]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "CV_easy_lgbm = GridSearchCV(estimator=easy_lgbm, param_grid=param_grid, cv= 5,n_jobs = 1)\n",
        "CV_easy_lgbm.fit(X_train_svm,y_train_svm)\n",
        "\n",
        "CV_easy_lgbm.best_params_"
      ],
      "metadata": {
        "id": "kJyhgQHaw7sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_easy_lgbm = EasyEnsembleClassifier(base_estimator= LGBMClassifier(random_state=42), n_estimators=250, n_jobs=1,\n",
        "                       random_state=42, replacement=True,\n",
        "                       sampling_strategy='auto', verbose=0,\n",
        "                       warm_start=True)\n",
        "print('Dengan menggunakan model easy ensemble classifier yang telah di tuned,')\n",
        "tuned_easy_lgbm.fit(X_train_svm,y_train_svm)\n",
        "evaluate(tuned_easy_lgbm, X_test_svm, y_test_svm)"
      ],
      "metadata": {
        "id": "3GXXEkxg0wYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc_roc_curve(tuned_easy_lgbm, X_test_svm, y_test_svm, X_train_svm, y_train_svm)"
      ],
      "metadata": {
        "id": "Y9kx8w8v5UFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari hasil evaluasi beberapa model, maka diperoleh model EasyEnsembleClassifier yang\n",
        "memiliki nilai akurasi yang paling baik. Selanjutnya dilakukan interpretasi pada model\n",
        "dengan melihat feature importance-nya"
      ],
      "metadata": {
        "id": "O43SfFMtS_bX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importances"
      ],
      "metadata": {
        "id": "wLefC-o3PMiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELI5 adalah paket Python yang membantu menunjukkan kepada kita kontribusi setiap fitur dalam memprediksi output. Kita dapat menggunakan show_weight untuk menunjukan bobot yang diberikan untuk setiap fitur dalam prediksi."
      ],
      "metadata": {
        "id": "nYPRQp4ATmuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eli5_permutation = PermutationImportance(estimator = tuned_easy_lgbm, scoring = 'f1', random_state=42, n_iter = 5)\n",
        "eli5_permutation.fit(X_test_svm, y_test_svm)"
      ],
      "metadata": {
        "id": "P4KfQ9EnyTjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eli5_permutation.feature_importances_.T.reshape(-1,1)"
      ],
      "metadata": {
        "id": "4CQUDeddy9Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eli5.show_weights(eli5_permutation, feature_names = X.columns.to_list())"
      ],
      "metadata": {
        "id": "0ZaHJibYy9iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_with_eli5=pd.DataFrame(np.hstack((np.array([X.columns[0:]]).T, eli5_permutation.feature_importances_.T.reshape(-1,1))), columns=['feature', 'importance'])\n",
        "feature_importance_with_eli5['importance']=pd.to_numeric(feature_importance_with_eli5['importance'])\n",
        "feature_importance_with_eli5.sort_values(by='importance', ascending=False)"
      ],
      "metadata": {
        "id": "y6gXPqCbzBnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,8))\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "# We sort by importance and get the features\n",
        "sns.barplot(x = 'importance', y = 'feature', data = feature_importance_with_eli5, \n",
        "            order = feature_importance_with_eli5.sort_values('importance', ascending=False).feature) "
      ],
      "metadata": {
        "id": "mjwbkB3dzCXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan feature importance nya, kandidat dapat diseleksi berdasarkan 4 hal terpenting yaitu:\n",
        "1. CDI:\n",
        "kandidat yang harus dipertimbangkan berasal dari kota-kota berkembang. Hasil menunjukan bahwa target kandidat dengan CDI 0.6 lebih serius daripada kandidat dengan CDI 0.9\n",
        "\n",
        "2. Relevant Experience:\n",
        "Kandidat dengan pengalaman yang relevan lebih serius mengikuti pelatihan\n",
        "\n",
        "3. Company Type:\n",
        "Kandidat yang bekerja di perusahaan kecil (small enterprise) lebih serius mengikuti pelatihan.\n",
        "\n",
        "4. Company Size:\n",
        "Kandidat yang bekerja di perusahaan sektor Pvt Ltd lebih serius mengikuti pelatihan."
      ],
      "metadata": {
        "id": "g7C9FuAxUEYX"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Rizca - HR Analytics : Job Change of Data Scientists",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}